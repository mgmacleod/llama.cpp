# Llama.cpp fork 

This is a fork of llama.cpp, the LLM inference engine. It's mostly focused on research in mechanistic interpretability with local models. 